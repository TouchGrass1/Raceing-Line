{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkHrcHfy1tYi/kwCZh8Rd3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TouchGrass1/Raceing-Line/blob/main/Nea_pseudo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQyYXHQ8B1mN"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find track boundaries"
      ],
      "metadata": {
        "id": "ZmDqrktcB5_B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the first step taken when a new track is presented. This type of calculation is static and will never change (unless the resolution of the image changes) as a result I can save the final produced array as a numpy binary file to save time having to calculate repeatedly\n",
        "To find the track boundaries I used a flood fill method, this method works but may not be the most effective as it relies on the back ground being white, the track being black and the fact that there is some from of grey within the image due to \"smoothing\" features. The algorithm makes its way clockwise around the track finding grey pixels to add to the boundaries."
      ],
      "metadata": {
        "id": "Mna7uCJAJYfb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first the neighbours of the starting pixel (predefined to be blue for outer boundary and green for the inner boundary)"
      ],
      "metadata": {
        "id": "hPCdCXqEKdq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_candidate_neighbors(node, size) #size is specifies the search radius to look for a neighbour\n",
        "  cx, cy = node\n",
        "  offset = size // 2\n",
        "  return [(cx + dx - offset, cy + dy - offset) for dx in range(size) for dy in range(size)] #returns a grid of potential neighbours\n"
      ],
      "metadata": {
        "id": "fEkyEHaRCdFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flood_fill(img_arr, start_blue, start_green):\n",
        "  sets = [set(), set()]\n",
        "  sets[0].add((start_blue[0], start_blue[1]))\n",
        "  sets[1].add((start_green[0], start_green[1]))\n",
        "  for i, pixel_set in enumerate(sets):\n",
        "    while pixel_set:\n",
        "      node = pixel_set.pop()\n",
        "      img_arr[node] = colours[i]\n",
        "\n",
        "      for nx, ny in get_candidate_neighbors(node, size=5):\n",
        "        if x,y within img array:\n",
        "          if x,y not in set:\n",
        "            pixel_set.add((int(nx), int(ny)))\n",
        "    order = find_order(img_arr, start_blue, start_green, colours)\n"
      ],
      "metadata": {
        "id": "nALj81cxK_xm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_order(img_arr, start_blue, start_green):\n",
        "  order = [[start_blue], [start_green]] #does outer then inner boundaries\n",
        "    for i in range(2):\n",
        "        run = True\n",
        "        while run:\n",
        "            node = order[i][-1] #picks the latest node\n",
        "            closest = None\n",
        "            closest_dist = float(\"inf\")\n",
        "\n",
        "            for size in [3, 5, 11]: #progressivly increase search radius, helps improve speeds\n",
        "                neighbors = TrackProcessor.get_candidate_neighbors(node, size=size) #find neighbours\n",
        "                for neighbor in neighbors:\n",
        "                    if ( neighbour within the bounds of the img_arr):\n",
        "                        if np.array_equal(img_arr[neighbor[0], neighbor[1]], colours[i]):\n",
        "                            dist = hypot(node[0] - neighbor[0], node[1] - neighbor[1])\n",
        "                            if 0 < dist < closest_dist:\n",
        "                                closest = (neighbor[0], neighbor[1])\n",
        "                                closest_dist = dist\n",
        "                                if closest_dist == 1:\n",
        "                                    break\n",
        "                if closest is not None:\n",
        "                    if size == 11:\n",
        "                        TrackProcessor.join_gap(order[i][-1], closest)\n",
        "                    break\n",
        "\n",
        "            if closest is None:\n",
        "                run = False\n",
        "            else:\n",
        "                order[i].append(closest)\n",
        "  check_return_to_start(order, start_blue, start_green)"
      ],
      "metadata": {
        "id": "dIeQJ2lGMC7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def check_return_to_start(order, start_blue, start_green):\n",
        "  if hypot(start and last) < root2:\n",
        "    return True\n",
        ""
      ],
      "metadata": {
        "id": "Fp5DmDP6Nv32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def join_gap(node1, node2): #joins any gaps within the finalised boundaries\n",
        "  draw.line(node1,node2)"
      ],
      "metadata": {
        "id": "YPHBQ6oMLxeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Resample track boundaries and generate mesh"
      ],
      "metadata": {
        "id": "7Z3zc1LqCQA0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I need to resample the track boundaries because the original track boundaries list is of different lengths because the outer boundary is larger and therefore has more pixels(nodes), however during caluations both lists need to be of the same dimensions\n",
        "\n",
        "the first method I tried was to find the arc lengths of both boundaries and lerp both of them individually with a fixed amount of points"
      ],
      "metadata": {
        "id": "R7IKqvLRCyA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def resampleBoundary(order, spacing): #ensures that both boundaries have the same number of points and are evenly spaced\n",
        "  inner, outer = order #splits the order into inner and outer boundaries\n",
        "  x,y = inner[:,0], inner[:,1] #splits into x and y coords\n",
        "\n",
        "  distances = sqrt(diff(x)**2 + diff(y)**2) #distance formula\n",
        "  sum = cumsum(distances) #cumulative sum, total length\n",
        "\n",
        "  num_points = sum/spacing #spacing is the distance between each point\n",
        "\n",
        "  new_x = interpolate(target_distance, sum, x) #linear interpolation of x\n",
        "  new_y = ... #same as x"
      ],
      "metadata": {
        "id": "y1harPHHCxU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "however this casued slipage as during bends the inside curve traveled further causing the nodes to get ahead and cause warping to the mesh\n",
        "\n",
        "so I tried to normalise both arcs and then create the nodes in proportion to the inner arc.\n",
        "\n",
        "this helped signifcantly and the slipage was reduced however the warping of the mesh was stil noticible\n",
        "\n",
        "The next method I tried was more mathmatically robust, this method find the normal to the inner arcs' nodes and then calculates the corresponding node on the outer arc"
      ],
      "metadata": {
        "id": "wfCyQY79DrJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unit_tangent_normal(pts)\n",
        "  m = gradient(pts) #numpy command to find first derivites of the points\n",
        "  tangent = m/ magnitude(m) #unit tangent given as a 1x2 matrix [x, y]\n",
        "  normal = ([-T[1], T[0]]) #90deg rotation to find normals"
      ],
      "metadata": {
        "id": "cu1s518GEstB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def line_projection_intersection(inner, outer, normal)# projects a normal line from inner arc to the outer arc\n",
        "  corresponding_pts = []\n",
        "  for i, (p, N) in enumerate(zip(normal,inner)): #zip matches inner and its corresponding normal\n",
        "    best_dist = inf\n",
        "    best_pt = None # the line will intersect with other points on the outer boundary, only want the closest one\n",
        "    k = N[0]*p[0] + N[1]*p[1] #line constant\n",
        "    for pt in outer:\n",
        "      c = N[0]*pt[0] + N[1]*pt[1]\n",
        "      if k == c: #point lies on the line\n",
        "          len = np.hypot(pt[0]-p[0], pt[1]-p[1])\n",
        "          if len < best_dist:\n",
        "              best_dist = len\n",
        "              best_pt = pt\n",
        "  corresponding_pts.append(best_pt)\n",
        "  return corresponding_pts\n"
      ],
      "metadata": {
        "id": "eXD2epk-FU5q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This method allowed me to produce the perfect mesh"
      ],
      "metadata": {
        "id": "hNxMAWxiHveN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "However after more thorough research into bezier curves and splines and the sad realization that all the track images I found did not include details on varying track widths (the images depicted that all tracks had a fixed track width), I decided to use the flood fill method to only find the mid line arc of the track and extrolpolate the inner and outer boundaries using a predetermined track width. I was willing to make the trade of losing a higher accuracy of the track itself with a more detailed and higher resolution mesh that is hopefully less computationally expensive because I never could have accessed the track width in the first place."
      ],
      "metadata": {
        "id": "O_jPU_4uPzhF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate track purely through bezier curves"
      ],
      "metadata": {
        "id": "sYY8oRgMSgs3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: ensure image is in grayscale\n",
        "\n",
        "Step 2: use skimage.skeletonization to extract the centerline\n",
        "\n",
        "Step 3: simplify path, only want a small sample of points\n",
        "\n",
        "Step 4: Fit a b-spline to the sampled points (allows for better curvature continuity)\n",
        "\n",
        "Step 5: find local cooridinates that are ofset from the curve"
      ],
      "metadata": {
        "id": "4bKo44QmUmAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img.grayscale\n",
        "skeleton = skeletonize(img)\n",
        "epsilon = 5 #space between each sample\n",
        "approx = appoxPolyDP(skeleton, epsilon, closed = True) #samples but ensures it picks points with more importance"
      ],
      "metadata": {
        "id": "IZolXjIDUkdt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "generating b-spline"
      ],
      "metadata": {
        "id": "PhB-LbI7qkBU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_b_spline(centerline, degree=3, close=True):\n",
        "  initialize curve\n",
        "  set degrees\n",
        "  autogenerate knot vectors\n",
        "  evaluate curve"
      ],
      "metadata": {
        "id": "6WgNSswxqm6e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To determine the local coordinates offset from the curve we need: normal vector of each point\n",
        "with this we can move along the normal vector a desired distance to determine boundaries and mesh points"
      ],
      "metadata": {
        "id": "cQ_JxuaOpZvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nurbs.operations.normal(curve)\n",
        "trackWidth = 70 #pixels\n",
        "meshRes = 10 #number of points per row\n",
        "scale = trackWidth/meshRes\n",
        "for i in range(meshRes):\n",
        "    mesh_row = []\n",
        "      for point in curve:\n",
        "          new_pt = scale*curve.normal.normalisedVector + point\n",
        "          mesh_row.append(new_pt)\n",
        "    mesh.append(mesh_row)\n"
      ],
      "metadata": {
        "id": "vLew_VZerk9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Caculate curvature"
      ],
      "metadata": {
        "id": "rKHJDUPuCVuJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numerator = dotproduct(curve.velocity, curve.acceleration)\n",
        "denomerator = curve.velocity ^ 3\n",
        "k  = numerator/ denomerator"
      ],
      "metadata": {
        "id": "TdynWKkurTr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimize pseudo above to use matrix multiplications rather than looping over each point individually"
      ],
      "metadata": {
        "id": "k17KHn8OtRxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "radius = 1/k"
      ],
      "metadata": {
        "id": "6VSREvd9ti0C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculating time\n",
        "time taken to traverse the track along that specific spline"
      ],
      "metadata": {
        "id": "_1_JdJu-tlrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "first we need to create a sample spline, to do this\n",
        "select a random point from each row of the mesh and generate a spline from it, then calculate the curvature to find the 'radius'"
      ],
      "metadata": {
        "id": "qBJ-LspNtztg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with a sample spline generated with know curvature we can apply the physic formulas"
      ],
      "metadata": {
        "id": "1naDjkyiuFD5"
      }
    }
  ]
}